---
title: "hw04_jrhaag2"
author: "Jeffery Haag"
date: "10/3/2020"
output:
  html_document:
    theme: readable
    toc: yes
---
## Exercise 1 (Using `lm` for Inference)
**(a)**
```{r}
faithful_model = lm(eruptions ~ waiting, data = faithful)
# plot(eruptions ~ waiting, data = faithful)
# abline(faithfulModel1, lwd = 3)
summary(faithful_model)

```

The null hypothesis is that B1  = 0 and alternative hypothesis is B1 != 0. The test statistic is 34.09. P value is 
p < 2.2e-16 .  We reject the null at alpha =0.01. The wait time is a signifigant factor of eruption time for old faithful geyser. They are almost ceartainly related.

**(b)**
```{r}
confidence_rad = 0.01*.4965
confint(faithful_model, level=0.99)
confidence_rad

```
The confidence interval is 0.0698727  to 0.0813832. This means that we are 99% confident that for an increaase of 1 minute wait time the eruption will increase withing that range above. Also it doesnt include zero so we can reject the null at 99%.

**(c)**
```{r}
confint(faithful_model, level=0.9)
confidence_rad

```
The confidence interval is -2.13833519  -1.60969678. This means that we are 90% confident that at wait time zero we expect a negative eruption time within the above range. Since this range doesn't include 0 we can reject the null at 90%.

**(d)**
```{r}
wait_times = data.frame(waiting = c(75,80))
predict(faithful_model, newdata = wait_times, interval = c("confidence"), level = 0.95)

```
THe interval for 75 is 3.736159 to 3.860002 with mean 3.79808  and for 80 is 4.104848 to 4.247592 with mean 4.17622. The range for 80 is bigger because it is farther away from the norm so we are less ceartain. The expexted error is bigger and our interval scales off that.

**(e)**
```{r}
wait_times_e = data.frame(waiting = c(75,100))
predict(faithful_model, newdata = wait_times_e, interval = c("prediction"), level = 0.95)

```
For 75 the eruption will be 2.818592 to 4.777569 minutes and for 100 it will be 4.701239 to 6.676319 minutes.

**(f)**
```{r}
wait_times_f = seq(min(faithful$waiting), max(faithful$waiting), by = 0.01)
faithful_rad = predict(faithful_model, newdata = data.frame(waiting = wait_times_f), 
                       interval = ("confidence"), level = 0.95)

faithful_rad2 = predict(faithful_model, newdata = data.frame(waiting = wait_times_f), interval = c("prediction"), level = 0.95)

plot(eruptions ~ waiting, data = faithful,
     xlab = "time to wait(minutes)",
     ylab = "time of eruption(minutes)",
     main = "Eruption time vs wait time")
abline(faithful_model, lwd = 2, col = "red")

lines(wait_times_f, faithful_rad[,"lwr"], col = "dodgerblue", lwd = 3, lty = 2)
lines(wait_times_f, faithful_rad[,"upr"], col = "dodgerblue", lwd = 3, lty = 2)
lines(wait_times_f, faithful_rad2[,"lwr"], col = "dodgerblue", lwd = 3, lty = 3)
lines(wait_times_f, faithful_rad2[,"upr"], col = "dodgerblue", lwd = 3, lty = 3)


```

## Exercise 2 (Using `lm` for Inference)

**(a)**
```{r}
library(faraway)
cholesterol_model = lm(chol ~ weight, data = diabetes)

summary(cholesterol_model)
print("Anova Table")
anova(cholesterol_model)
```

THe null hypotheses is that B1 = 0. Alternative is B1 doesn't = 0. The test statistic is 1.793. The p value is .1813.
We cannot reject the null at alpha=0.05. From this we cannot say that weight and cholesterol are significantly related to each other.

**(b)**
```{r}
library(faraway)
cholesterol_model2 = lm(hdl ~ weight, data = diabetes)

summary(cholesterol_model2)
print("Anova Table")
anova(cholesterol_model2)
```
THe null hypotheses is that B1 = 0. Alternative is B1 doesn't = 0. The test statistic is 36.91 The p value is 2.891e-09 We can reject the null at alpha=0.05. From this we can confidently say that weight and HDL cholesterol are significantly related to each other.

## Exercise 3 (Inference "without" `lm`)

```{r}
goalies = read.csv("goalies.csv")
goalie_model = lm(W ~ MIN, data = goalies)

summary(goalie_model)
estimate = 7.846e-03;
std_err = 5.071e-05;
estimate;
std_err;
n = length(fitted(goalie_model))
t = (estimate - 0.008)/(std_err);
t
f=n-2
f
p = pt(t, df=n-2)
p
```
B1 is .007846. Std error of B1 is 5.071e-5. The t test is  -3.036876. The degrees of freedom 711. P value is 0.001238923. We can reject the null at alpha =0.01. 

## Exercise 4 (Simulating Sampling Distributions)
**(a)**
```{r}
uin = 673856275
set.seed(uin)
n = 50
x = seq(0, 20, length = n)
beta_0_hats = rep(0, 1500);
beta_1_hats = rep(0, 1500);


for (i in 1:1500) {
  eps = rnorm(50, mean = 0, sd = 5)
  y   = 4 + 0.5 * x + eps
  
  sim_model = lm(y ~ x)
  
  beta_0_hats[i] = coef(sim_model)[1]
  beta_1_hats[i] = coef(sim_model)[2]
  
  
}

```

**(b)**

THe expected answer for B1hat is 0.5 because that is what b1 is in the random simulation

**(c)**
```{r}
Sxx = sum((x - mean(x)) ^ 2)
sdc = 5 / sqrt(Sxx)
sdc
```

The expected std dev is 0.120049.

**(d)**
```{r}
avgb1 = mean(beta_1_hats)
avgb1
```
I got 0.5011638 for the mean of B1 simulated and this makes sense because it is pretty close to the expected value.

**(e)**
```{r}
sdb1 = sd(beta_1_hats)
sdb1
```

I got 0.1195394, this is extremely close to my answer in C so it makes sense

**(f)**
The expected value of B0hat is 4.

**(g)**
```{r}
sdg = 5 ^ 2 * (1 / n + mean(x) ^ 2 / Sxx)
sdg = sqrt(sdg)
sdg
```
My expected sd is 1.393

**(h)**
```{r}
meanh = mean(beta_0_hats)
meanh
```
3.999 makes sense because it is very close to expected value of 4

**(i)**
```{r}
sdh = sd(beta_0_hats)
sdh
```
Yes this makes sense it is very close to expected value.

**(j)**
```{r}
hist(beta_1_hats, prob = TRUE)
var = 25 / Sxx
curve(dnorm(x, mean = 0.5, sd = sqrt(var)), add = TRUE)
```

**(k)**
```{r}
hist(beta_0_hats, prob = TRUE, breaks = 30, xlab = "B0hat")
var_beta_0_hat = 5 * sqrt((1 / 50) + (mean(x) ^ 2 / Sxx))
curve(dnorm(x, mean = 4, sd = sqrt(var_beta_0_hat)), add = TRUE)
```

## Exercise 5 (Simulating Confidence Intervals)

**(a)**
```{r}
uin = 673856275
set.seed(uin)
n = 20
x = seq(-5, 5, length = n)
beta_0_hats = rep(0, 2000);
se = rep(0, 2000);

lower_90 = rep(0, 2000);
upper_90 = rep(0, 2000);
Sxx = sum((x - mean(x)) ^ 2);
crit_val = qt(0.95, df = n - 2)


for (i in 1:2000) {
  eps = rnorm(20, mean = 0, sd = 4)
  y   = 1 + 3 * x + eps
  
  sim_model = lm(y ~ x)
  
  
  
  beta_0_hats[i] = coef(sim_model)[1];
  # se[i] = coef(sim_model)[2];
  se[i] = summary(sim_model)$sigma;
  # se[i] = summary(sim_model)$coefficient[1,2]
  
}

```

**(b)**
```{r}


for (i in 1:2000) {
  
  
  SE = se[i] * sqrt((1/n) + (mean(x)^2/Sxx));
  margin = crit_val * SE;
  lower_90[i] = beta_0_hats[i] - margin;
  upper_90[i] = beta_0_hats[i] + margin;
  
}

```
**(c)**
```{r}
sum = 0;
for (i in 1:2000)
{
  if ( lower_90[i]< 1 && upper_90[i] > 1)
    sum = sum +1;
}
# sum
ans= sum / 2000;
ans
```
**(d)**
```{r}
sum = 0;
for (i in 1:2000)
{
  if ( lower_90[i]< 0 && upper_90[i] > 0)
    sum = sum +1;
}
# sum
ans= sum / 2000;
1 - ans
```

**(e)**
```{r}
lower_99 = rep(0, 2000);
upper_99 = rep(0, 2000);

crit_vale = qt(0.99, df = n - 2)


for (i in 1:2000) {
  
  
  SE = se[i] * sqrt((1/n) + (mean(x)^2/Sxx));
  margin = crit_vale * SE;
  lower_99[i] = beta_0_hats[i] - margin;
  upper_99[i] = beta_0_hats[i] + margin;
  
}


```


**(f)**
```{r}


sum = 0;
for (i in 1:2000)
{
  if ( lower_99[i]< 1 && upper_99[i] > 1)
    sum = sum +1;
}
# sum
ans= sum / 2000;
ans
```

**(f)**
```{r}


sum = 0;
for (i in 1:2000)
{
  if ( lower_99[i]< 0 && upper_99[i] > 0)
    sum = sum +1;
}
# sum
ans= sum / 2000;
1 - ans
```













